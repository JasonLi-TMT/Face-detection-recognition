{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import dlib   ### dlib is a powerful C++ db link: http://blog.dlib.net/2017/02/high-quality-face-recognition-with-deep.html\n",
    "import glob\n",
    "import os\n",
    "from skimage import io\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"define path to pretrained model & data\"\"\"\n",
    "\n",
    "\n",
    "doc_path = \"/Users/zishuoli/Downloads/Deep_learning/SYSTEMatrix\"\n",
    "face_rec_model_path = doc_path + \"/pretrained_model/dlib_face_recognition_resnet_model_v1.dat\"\n",
    "predictor_path = doc_path + \"/pretrained_model/shape_predictor_68_face_landmarks.dat\"\n",
    "\n",
    "faces_folder_path = doc_path + \"/image\"\n",
    "\n",
    "\n",
    "\"\"\"Generate detector, predictor, facerecognizer\"\"\"\n",
    "#1 detector: detect face   input: dets eg:[[(115, 116) (223, 223)]]\n",
    "#2 predictor: predict shape   input: eg: predictor(img, dets[0])\n",
    "#3 facrec: generate feature array .   input: eg:\n",
    "\n",
    "\"\"\"code eg:\n",
    "img = io.imread(f)\n",
    "dets = detector(img, 1)  # length of dets means number of face detected\n",
    "for i in range(len(dets)):\n",
    "    shape = predictor(img, dets[i])\n",
    "    face_descriptor = facerec.compute_face_descriptor(img, shape)\n",
    "    \n",
    "\"\"\"\n",
    "\n",
    "detector = dlib.get_frontal_face_detector()\n",
    "predictor = dlib.shape_predictor(predictor_path)\n",
    "facerec = dlib.face_recognition_model_v1(face_rec_model_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing file: /Users/zishuoli/Downloads/WechatIMG27.jpeg\n",
      "Number of faces detected: 1\n",
      "Detection 0: Left: 245 Top: 40 Right: 707 Bottom: 502\n",
      "feature dimention (128, 1)\n"
     ]
    }
   ],
   "source": [
    "# \"\"\"step\"\"\"\n",
    "###1\n",
    "\n",
    "win = dlib.image_window()\n",
    "\n",
    "for f in glob.glob(os.path.join(\"/Users/zishuoli/Downloads/\", \"*.jpeg\")):\n",
    "    print(\"Processing file: {}\".format(f))\n",
    "    img = io.imread(f)\n",
    "\n",
    "    win.clear_overlay()\n",
    "    win.set_image(img)\n",
    "\n",
    "    # Ask the detector to find the bounding boxes of each face. The 1 in the\n",
    "    # second argument indicates that we should upsample the image 1 time. This\n",
    "    # will make everything bigger and allow us to detect more faces.\n",
    "    dets = detector(img, 1)\n",
    "    print(\"Number of faces detected: {}\".format(len(dets)))\n",
    "\n",
    "    # Now process each face we found.\n",
    "    for k, d in enumerate(dets):\n",
    "        print(\"Detection {}: Left: {} Top: {} Right: {} Bottom: {}\".format(\n",
    "            k, d.left(), d.top(), d.right(), d.bottom()))\n",
    "        # Get the landmarks/parts for the face in box d.\n",
    "        shape = predictor(img, d)\n",
    "        # Draw the face landmarks on the screen so we can see what face is currently being processed.\n",
    "        win.clear_overlay()\n",
    "        win.add_overlay(d)\n",
    "        win.add_overlay(shape)\n",
    "\n",
    "\n",
    "        face_descriptor = facerec.compute_face_descriptor(img, shape)\n",
    "        print(\"feature dimention\",face_descriptor.shape)\n",
    "\n",
    "        dlib.hit_enter_to_continue()"
   ]
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python [default]",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
